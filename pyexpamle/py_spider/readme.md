# python爬虫

## 1. 最基本抓站
1.1 使用正则
  + [抓取服务器代理](./pyspider_v1_01.py)
  + [抓取网站图片](./pyspider_v1_02.py)
2. 使用代理服务器
3. 需要登录的情况 
    3.1 cookie的处理
    3.2 表单的处理
    3.3 伪装浏览器访问
    3.4 反"反盗链"
    3.5 终极绝招
4. 多线程并发抓取
5. 验证码处理
6. gzip/deflate支持
7. 更方便的多线程
    7.1 用twisted进行异步I/O抓取
8. 一些琐碎的经验
    8.1 连接池
    8.2 设定线程的栈大小
    8.3 设置失败自动重连
    8.4 设置超时
    8.5 登陆
9. 总结

[参考链接](http://wenku.baidu.com/link?url=KGeZwk8lKp6Mor5vkTjrikv1dSjLLhzBmNdHOYCMXGI42LRRKJFWLwB7Sc0LW8OhbBqN88gzOyrLbdGDwu3TDRRNUqZBvmRqpPVA2ox29km)